{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9ed442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [28/Oct/2023 11:46:59] \"OPTIONS /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Request 'http://127.0.0.1:5000/predict' [POST]>\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "(1, 128, 5)\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "[[0.3746192]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/Oct/2023 11:47:18] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Researching the stock market is a complex process that requires a deep understanding of the market and the individual companies that are traded on it. In order to make informed decisions, investors need to conduct rigorous research and analysis to assess the current and future performance of the stocks they are considering.\n",
      "\n",
      "<b>Stock Market Advice Based on 118.88 for GOOG:</b>\n",
      "\n",
      "Given the current stock price of 118.88 for GOOG, investors should consider the company's recent performance, news, and market trends in order to make an informed decision. GOOG is a technology giant that has seen significant growth over the past few years. As such, investors should look at the company's financials and its competitive landscape to get a better understanding of the company's prospects. Additionally, investors should consider the current macroeconomic environment and the impact that it could have on the stock.\n",
      "\n",
      "<b>Research Areas to Take Decision:</b>\n",
      "\n",
      "In order to make an informed decision, investors should consider the following research areas: \n",
      "\n",
      "1. Fundamental Analysis: Fundamental analysis involves analyzing a company's financials and performance to determine its value. This includes looking at the company's balance sheet, income statement, and cash flow statement. Additionally, investors should consider the company's competitive landscape and the impact that it could have on the stock. \n",
      "\n",
      "2. Technical Analysis: Technical analysis involves looking at the stock's past performance and trends in order to predict future movements. This includes looking at the stock's price, volume, and other indicators. \n",
      "\n",
      "3. Macroeconomic Analysis: Macroeconomic analysis involves looking at the broader economic environment and the impact that it could have on the stock. This includes looking at the current economic conditions, interest rates, inflation, and other factors. \n",
      "\n",
      "4. Sentiment Analysis: Sentiment analysis involves looking at the public's opinion of the stock. This includes looking at news articles, analyst reports, and other sources to determine the overall sentiment towards the stock. \n",
      "\n",
      "<b>Suggestion:</b>\n",
      "\n",
      "Given the current stock price of 118.88 for GOOG, investors should conduct rigorous research and analysis to assess the current and future performance of the stock. This includes looking at the company's financials, the competitive landscape, the macroeconomic environment, and the public's opinion of the stock. Additionally, investors should consider the stock's past performance and trends in order to make an informed decision. Ultimately, investors should make sure to diversify their portfolios and not invest in any one stock.\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re \n",
    "import yfinance as yf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "# Create a Flask web application\n",
    "app = Flask(__name__)\n",
    "\n",
    "class Time2Vector(Layer):\n",
    "    def __init__(self, seq_len, **kwargs):\n",
    "        super(Time2Vector, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        '''Initialize weights and biases with shape (batch, seq_len)'''\n",
    "        self.weights_linear = self.add_weight(name='weight_linear',\n",
    "                                    shape=(int(self.seq_len),),\n",
    "                                    initializer='uniform',\n",
    "                                    trainable=True)\n",
    "\n",
    "        self.bias_linear = self.add_weight(name='bias_linear',\n",
    "                                    shape=(int(self.seq_len),),\n",
    "                                    initializer='uniform',\n",
    "                                    trainable=True)\n",
    "\n",
    "        self.weights_periodic = self.add_weight(name='weight_periodic',\n",
    "                                    shape=(int(self.seq_len),),\n",
    "                                    initializer='uniform',\n",
    "                                    trainable=True)\n",
    "\n",
    "        self.bias_periodic = self.add_weight(name='bias_periodic',\n",
    "                                    shape=(int(self.seq_len),),\n",
    "                                    initializer='uniform',\n",
    "                                    trainable=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        '''Calculate linear and periodic time features'''\n",
    "        x = tf.math.reduce_mean(x[:,:,:4], axis=-1)\n",
    "        time_linear = self.weights_linear * x + self.bias_linear # Linear time feature\n",
    "        time_linear = tf.expand_dims(time_linear, axis=-1) # Add dimension (batch, seq_len, 1)\n",
    "\n",
    "        time_periodic = tf.math.sin(tf.multiply(x, self.weights_periodic) + self.bias_periodic)\n",
    "        time_periodic = tf.expand_dims(time_periodic, axis=-1) # Add dimension (batch, seq_len, 1)\n",
    "        return tf.concat([time_linear, time_periodic], axis=-1) # shape = (batch, seq_len, 2)\n",
    "\n",
    "    def get_config(self): # Needed for saving and loading model with custom layer\n",
    "        config = super().get_config().copy()\n",
    "        config.update({'seq_len': self.seq_len})\n",
    "        return config\n",
    "    \n",
    "class SingleAttention(Layer):\n",
    "    def __init__(self, d_k, d_v):\n",
    "        super(SingleAttention, self).__init__()\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.query = Dense(self.d_k,\n",
    "                           input_shape=input_shape,\n",
    "                           kernel_initializer='glorot_uniform',\n",
    "                           bias_initializer='glorot_uniform')\n",
    "\n",
    "        self.key = Dense(self.d_k,\n",
    "                         input_shape=input_shape,\n",
    "                         kernel_initializer='glorot_uniform',\n",
    "                         bias_initializer='glorot_uniform')\n",
    "\n",
    "        self.value = Dense(self.d_v,\n",
    "                           input_shape=input_shape,\n",
    "                           kernel_initializer='glorot_uniform',\n",
    "                           bias_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, inputs): # inputs = (in_seq, in_seq, in_seq)\n",
    "        q = self.query(inputs[0])\n",
    "        k = self.key(inputs[1])\n",
    "\n",
    "        attn_weights = tf.matmul(q, k, transpose_b=True)\n",
    "        attn_weights = tf.map_fn(lambda x: x/np.sqrt(self.d_k), attn_weights)\n",
    "        attn_weights = tf.nn.softmax(attn_weights, axis=-1)\n",
    "\n",
    "        v = self.value(inputs[2])\n",
    "        attn_out = tf.matmul(attn_weights, v)\n",
    "        return attn_out\n",
    "\n",
    "#############################################################################\n",
    "\n",
    "class MultiAttention(Layer):\n",
    "    def __init__(self, d_k, d_v, n_heads):\n",
    "        super(MultiAttention, self).__init__()\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        self.n_heads = n_heads\n",
    "        self.attn_heads = list()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        for n in range(self.n_heads):\n",
    "            self.attn_heads.append(SingleAttention(self.d_k, self.d_v))\n",
    "\n",
    "            # input_shape[0]=(batch, seq_len, 7), input_shape[0][-1]=7\n",
    "            self.linear = Dense(input_shape[0][-1],\n",
    "                                input_shape=input_shape,\n",
    "                                kernel_initializer='glorot_uniform',\n",
    "                                bias_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        attn = [self.attn_heads[i](inputs) for i in range(self.n_heads)]\n",
    "        concat_attn = tf.concat(attn, axis=-1)\n",
    "        multi_linear = self.linear(concat_attn)\n",
    "        return multi_linear\n",
    "\n",
    "#############################################################################\n",
    "\n",
    "class TransformerEncoder(Layer):\n",
    "    def __init__(self, d_k, d_v, n_heads, ff_dim, dropout=0.1, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        self.n_heads = n_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.attn_heads = list()\n",
    "        self.dropout_rate = dropout\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.attn_multi = MultiAttention(self.d_k, self.d_v, self.n_heads)\n",
    "        self.attn_dropout = Dropout(self.dropout_rate)\n",
    "        self.attn_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)\n",
    "\n",
    "        self.ff_conv1D_1 = Conv1D(filters=self.ff_dim, kernel_size=1, activation='relu')\n",
    "        # input_shape[0]=(batch, seq_len, 7), input_shape[0][-1] = 7\n",
    "        self.ff_conv1D_2 = Conv1D(filters=input_shape[0][-1], kernel_size=1)\n",
    "        self.ff_dropout = Dropout(self.dropout_rate)\n",
    "        self.ff_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)\n",
    "\n",
    "    def call(self, inputs): # inputs = (in_seq, in_seq, in_seq)\n",
    "        attn_layer = self.attn_multi(inputs)\n",
    "        attn_layer = self.attn_dropout(attn_layer)\n",
    "        attn_layer = self.attn_normalize(inputs[0] + attn_layer)\n",
    "\n",
    "        ff_layer = self.ff_conv1D_1(attn_layer)\n",
    "        ff_layer = self.ff_conv1D_2(ff_layer)\n",
    "        ff_layer = self.ff_dropout(ff_layer)\n",
    "        ff_layer = self.ff_normalize(inputs[0] + ff_layer)\n",
    "        return ff_layer\n",
    "\n",
    "    def get_config(self): # Needed for saving and loading model with custom layer\n",
    "        config = super().get_config().copy()\n",
    "        config.update({'d_k': self.d_k,\n",
    "                       'd_v': self.d_v,\n",
    "                       'n_heads': self.n_heads,\n",
    "                       'ff_dim': self.ff_dim,\n",
    "                       'attn_heads': self.attn_heads,\n",
    "                       'dropout_rate': self.dropout_rate})\n",
    "        return config\n",
    "\n",
    "\n",
    "    # ... (Your TransformerEncoder code)\n",
    "\n",
    "def make_predict(df,companyTicker):\n",
    "#     df.drop(columns=['Date'], inplace=True)\n",
    "    x = df[:128]\n",
    "    x = x.values\n",
    "    x = x.reshape((1, 128, 5))\n",
    "    print(x.shape)\n",
    "    model = tf.keras.models.load_model(f\"{companyTicker}.hdf5\",\n",
    "                                   custom_objects={'Time2Vector': Time2Vector,\n",
    "                                                   'SingleAttention': SingleAttention,\n",
    "                                                   'MultiAttention': MultiAttention,\n",
    "                                                   'TransformerEncoder': TransformerEncoder})\n",
    "    pred = model.predict(x) \n",
    "    print(pred)\n",
    "    return pred\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    companyTicker = request.json.get('companyTicker') \n",
    "    print(request)\n",
    "    # Fetch the historical data using the provided ticker symbol\n",
    "    start_date = pd.Timestamp.now() - pd.DateOffset(days=200)\n",
    "    end_date = pd.Timestamp.now()\n",
    "    df = yf.download(companyTicker, start=start_date, end=end_date)\n",
    "    df = df.iloc[-128:]\n",
    "    selected_columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    df = df[selected_columns]\n",
    "\n",
    "    # Make the prediction\n",
    "    ClosingPrice = make_predict(df,companyTicker)\n",
    "    min_close = df['Close'].min()\n",
    "    max_close = df['Close'].max()\n",
    "    original_close = (ClosingPrice[0, 0] * (max_close - min_close)) + min_close\n",
    "    price = round(original_close, 2)\n",
    "    \n",
    "        #  chat gpt implementation\n",
    "\n",
    "    api_endpoint = \"https://api.openai.com/v1/completions\"\n",
    "    api_key =\"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\"\n",
    "\n",
    "    # Headers configuration\n",
    "    request_headers = {\n",
    "        'Content-Type' : 'application/json',\n",
    "        'Authorization': 'Bearer ' + api_key\n",
    "    }\n",
    "\n",
    "    # Configuring prompt\n",
    "    request_data= {\n",
    "        'model' : 'text-davinci-003',\n",
    "        'prompt' : \"mention research areas also Here is the predicted Stock price relate it to the company \"+str(price)  + \"for the ticker \" + companyTicker + \"generate a stock market advice based on this and tell me the research areas to take decision and what do you sugeest. describe using 500 words\",\n",
    "        'max_tokens':1000, \n",
    "        'temperature':0.5\n",
    "    }\n",
    "\n",
    "    # API call and storing response\n",
    "    response = requests.post(api_endpoint,headers=request_headers,json=request_data)\n",
    "\n",
    "    # if the response is success writing a JSON object\n",
    "    if response.status_code == 200:\n",
    "        print(response.json()['choices'][0]['text'])\n",
    "        data = response.json()['choices'][0]['text']\n",
    "\n",
    "     # if the response is unsuccess printing the status code\n",
    "    else:\n",
    "        print(f\"Request Failed with status code: {str(response.status_code)}\")\n",
    "\n",
    "    return f\"Predicted Closing Price for {companyTicker}: ${price} {data}\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, use_reloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec955861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2197d5a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
